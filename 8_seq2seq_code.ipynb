{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVPoPAzUSfZe"
      },
      "source": [
        "# Генерация кода по вопросам со StackOverflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2QRHle57SfZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a87724f-c737-49a7-88bf-b6335e646ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stepik-dl-nlp' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle,\n",
        "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
        "\n",
        "!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
        "import sys; sys.path.append('./stepik-dl-nlp')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dJqBQojfCRu",
        "outputId": "b7a2c461-282f-4dc5-a52e-fcdc66de445b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchtext) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KMffi7XOhghv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PdJ9ig8PSfZh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.legacy.datasets import TranslationDataset, Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('/content/stepik-dl-nlp/datasets/stackoverflow_code_generation/conala/conala-test.csv').head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xUXdSg6Khh3U",
        "outputId": "26321153-bad5-40f4-94ae-c6effd950847"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c5862cc7-40b6-48f4-a109-f49f2d33dcf0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intent</th>\n",
              "      <th>snippet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How can I send a signal from a python program?</td>\n",
              "      <td>os.kill(os.getpid(), signal.SIGUSR1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Decode Hex String in Python 3</td>\n",
              "      <td>bytes.fromhex('4a4b4c').decode('utf-8')</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>check if all elements in a list are identical</td>\n",
              "      <td>all(x == myList[0] for x in myList)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Format string dynamically</td>\n",
              "      <td>print('%*s : %*s' % (20, 'Python', 20, 'Very G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How to convert a string from CP-1251 to UTF-8?</td>\n",
              "      <td>d.decode('cp1251').encode('utf8')</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5862cc7-40b6-48f4-a109-f49f2d33dcf0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5862cc7-40b6-48f4-a109-f49f2d33dcf0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5862cc7-40b6-48f4-a109-f49f2d33dcf0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           intent                                            snippet\n",
              "0  How can I send a signal from a python program?               os.kill(os.getpid(), signal.SIGUSR1)\n",
              "1                   Decode Hex String in Python 3            bytes.fromhex('4a4b4c').decode('utf-8')\n",
              "2   check if all elements in a list are identical                all(x == myList[0] for x in myList)\n",
              "3                       Format string dynamically  print('%*s : %*s' % (20, 'Python', 20, 'Very G...\n",
              "4  How to convert a string from CP-1251 to UTF-8?                  d.decode('cp1251').encode('utf8')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HmTSMvEFSfZh"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь нам нужно написать токенизаторы, которые помогут нам поделить на токены вопросы со StackOverflow и кусочек кода.\n",
        "\n",
        "Функция \"tokenize_question\" токенизирует наш вопрос — делаем это с помощью простой регулярки. Кроме того, мы отрезаем слишком длинные слова, которые, скорее всего, являются названиями веб-сайтов, либо слишком длинными названиями каких-то текстовых полей. Кроме того, мы будем подавать наш вопрос в обратном порядке в нашу сеть. То есть, будем начинать с последнего слова и заканчивать первым\n",
        "\n",
        "Функция \"tokenize_snippet\" токенизирует кусочек кода. Работает она примерно так же, с помощью чуть другой регулярки, где мы перечисляем знаки пунктуации, которые нас могут интересовать. "
      ],
      "metadata": {
        "id": "RtTNTVaVgysb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VANV3qhVSfZh"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def tokenize_question(text):\n",
        "    \"\"\"\n",
        "    Tokenizes question from a string into a list of strings (tokens) and reverses it\n",
        "    \"\"\"\n",
        "    return list(filter(lambda x: len(x) < 16, re.findall(r\"[\\w']+\", text)[::-1]))\n",
        "\n",
        "def tokenize_snippet(text):\n",
        "    \"\"\"\n",
        "    Tokenizes code snippet into a list of operands\n",
        "    \"\"\"\n",
        "    return list(filter(lambda x: len(x) < 10, re.findall(r\"[\\w']+|[.,!?;:@~(){}\\[\\]+-/=\\\\\\'\\\"\\`]\", text)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь напишем обработчик входных данных с помощью библиотеки \"torchtext\". Field позволяет нам определить, как должны обрабатываться данные. Напишем два разных обработчика для вопросов на естественном языке и для кода.\n",
        "\n",
        "Field позволяет задать параметр tokenize, куда мы можем передать наши функции-токенизаторы отдельно для вопроса или для кода. В нашем примере, Field также добавит два дополнительных токена — это \"end of sequence\" и \"start of sequence\". Все токены будут приведены к нижнему регистру, а также, для вопроса, мы будем учитывать длину этого вопроса.\n",
        "\n",
        " Далее разделим наши данные на обучающую, валидационную и тестовую выборки и применили тоекнизацию "
      ],
      "metadata": {
        "id": "4xB-Cq1UjAlm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dHF8B_XcSfZi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.legacy import data, datasets\n",
        "\n",
        "SRC = data.Field(\n",
        "    tokenize = tokenize_question, \n",
        "    init_token = '<sos>', \n",
        "    eos_token = '<eos>', \n",
        "    lower = True,\n",
        "    include_lengths = True\n",
        ")\n",
        "\n",
        "TRG = data.Field(\n",
        "    tokenize = tokenize_snippet, \n",
        "    init_token = '<sos>', \n",
        "    eos_token = '<eos>', \n",
        "    lower = True\n",
        ")\n",
        "\n",
        "fields = {\n",
        "    'intent': ('src', SRC),\n",
        "    'snippet': ('trg', TRG)\n",
        "}\n",
        "\n",
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "                            path = './stepik-dl-nlp/datasets/stackoverflow_code_generation/conala/',\n",
        "                            train = 'conala-train.csv',\n",
        "                            validation = 'conala-valid.csv',\n",
        "                            test = 'conala-test.csv',\n",
        "                            format = 'csv',\n",
        "                            fields = fields\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сформируем словарь. Задаём максимально возможный размер слоя и минимальную встречаемость слова для того, чтобы попасть в словарь. Для вопроса мы выбираем минимальную встречаемость равную \"3\", для сниппета с кодом — \"5\". Эти числа можно вариировать и постараться подобрать такие, чтобы словарь выглядел наиболее адекватно — чтобы в нём не было мусорных слов, и чтобы, при этом, не отрезались слова, которые действительно несут некоторый смысл и помогут нам обучить более адекватную модель. "
      ],
      "metadata": {
        "id": "gyNlGEPxreti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WfpirPVySfZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c1696f-e365-4046-92cb-bb666c79bb4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('a', 1285), ('in', 949), ('python', 922), ('to', 851), ('how', 633), ('of', 602), ('list', 558), ('string', 397), ('the', 328), ('from', 275), ('with', 228), ('pandas', 192), ('i', 191), ('dictionary', 162), ('get', 151), ('convert', 134), ('values', 131), ('do', 125), ('dataframe', 111), ('into', 110)]\n",
            "[(')', 3480), ('(', 3475), ('.', 2595), (',', 1899), ('[', 1122), (']', 1121), ('=', 927), (\"'\", 885), ('\\\\', 697), (':', 587), ('in', 504), ('x', 498), ('\"', 496), ('for', 450), ('1', 377), ('-', 279), ('a', 265), ('0', 259), ('/', 257), ('df', 234)]\n",
            "Уникальные токены в словаре интентов: 612\n",
            "Уникальные токены в словаре сниппетов: 395\n"
          ]
        }
      ],
      "source": [
        "SRC.build_vocab([train_data.src], max_size=25000, min_freq=3)\n",
        "print(SRC.vocab.freqs.most_common(20))\n",
        "\n",
        "\n",
        "TRG.build_vocab([train_data.trg], min_freq=5)\n",
        "print(TRG.vocab.freqs.most_common(20))\n",
        "\n",
        "print(f\"Уникальные токены в словаре интентов: {len(SRC.vocab)}\")\n",
        "print(f\"Уникальные токены в словаре сниппетов: {len(TRG.vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Z2yqD6HASfZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8841ece-3ca9-4039-8df2-d7603d2438be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер обучающей выборки: 2000\n",
            "Размер валидационной выборки: 379\n",
            "Размер тестовой выборки: 500\n"
          ]
        }
      ],
      "source": [
        "print(f\"Размер обучающей выборки: {len(train_data.examples)}\")\n",
        "print(f\"Размер валидационной выборки: {len(valid_data.examples)}\")\n",
        "print(f\"Размер тестовой выборки: {len(test_data.examples)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FVFyqVh8SfZj"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.set_device(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxzMMJCusnCy",
        "outputId": "10765b12-0938-44e9-e4fe-ba4e40f72738"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Последний этап нашей простой предобработки данных — это создать итераторы. Мы хотим, чтобы итератор возвращал батчи с данными, у которых есть атрибут \"src\" — это тензоры, кодирующие входные предложения (вопросы на естественном языке) и атрибут \"trg\" (target) — это тензоры, кодирующие сниппеты с кодом. Под кодированием здесь понимается простое сопоставление токина его числовому индексу. Это соответствие, собственно, и прописано в слове.\n",
        "\n",
        "Мы будем использовать \"BucketIterator\", а не обычный итератор, потому что он минимизирует количество паддинга для входных и выходных предложений, что достаточно удобно в нашей задаче"
      ],
      "metadata": {
        "id": "1HUG8-Ulsh6U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ToL9mjBQSfZk"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 2\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_within_batch = True,\n",
        "     sort_key = lambda x : len(x.src),\n",
        "     device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь давайте подробнее рассмотрим код энкодера и декодера для нашей модели. Итак, энкодер, в нашем случае — это двухслойная LSTM.\n",
        "Для многослойной LSTM входная последовательность идёт в первый слой сети, а скрытое состояние первого слоя используется как входная последовательность следующего слоя. Скрытое состояние первого слоя можно представить формулой, зависящей от входных токенов и от предыдущего скрытого состояния. Напомню что, в отличие от RNN, LSTM, кроме того, что берёт на вход предыдущее скрытые состояние и возвращает следующее, ещё и принимает на вход так называемое \"cell state\". Его обычно обозначают буквой \"c\". Можно воспринимать его как другой вид скрытого состояния. В итоге, конечное представление входной последовательности в виде вектора будет конкатенацией скрытого состояния и нашего cell state, которое будем обозначать буквой \"с\" (поэтому в 20 строчке идет умножение на 2).\n",
        "\n",
        "GRU - многослоайный LSTM"
      ],
      "metadata": {
        "id": "-gyZ20GpuhVh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qbpXZnTMSfZk"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        \"\"\"\n",
        "        bidirectional отвечает за то — двунаправленная или однонаправленная сеть используется нашем примере.\n",
        "        там где dim - означаает размерность\n",
        "        :param emb_dim - размерность эмбендинга\n",
        "        enc_hid_dim - кол-во скрытых слоев в lstm\n",
        "        \"\"\"\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim \n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src = [src sent len, batch size]\n",
        "        #src_len = [src sent len]\n",
        "        #мы передаём входное предложение, которое превращено в dense-вектора с помощью\n",
        "        #эмбеддинг-слоя, и затем применяем дропаут \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src sent len, batch size, emb dim]\n",
        "        \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n",
        "        \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "                     \n",
        "        #packed_outputs is a packed sequence containing all hidden states\n",
        "        #hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "            \n",
        "        #outputs is now a non-packed sequence, all hidden states obtained\n",
        "        #  when the input is a pad token are all zeros\n",
        "            \n",
        "        #outputs = [sent len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs are always from the last layer\n",
        "        \n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        #  encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs = [sent len, batch size, enc hid dim * 2]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В нашем примере мы будем использовать attention. На коде attention не будем останавливаться подробно, скажем лишь, что здесь мы будем использовать стандартный attention, который посчитает нам веса по нашей входной последовательности."
      ],
      "metadata": {
        "id": "lu0a4PE800eW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WPu6aVofSfZl"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
        "        #mask = [batch size, src sent len]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat encoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden = [batch size, src sent len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        #energy = [batch size, src sent len, dec hid dim]\n",
        "                \n",
        "        energy = energy.permute(0, 2, 1)\n",
        "        \n",
        "        #energy = [batch size, dec hid dim, src sent len]\n",
        "        \n",
        "        #v = [dec hid dim]\n",
        "        \n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
        "        \n",
        "        #v = [batch size, 1, dec hid dim]\n",
        "            \n",
        "        attention = torch.bmm(v, energy).squeeze(1)\n",
        "        \n",
        "        #attention = [batch size, src sent len]\n",
        "        \n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Архитектура декодера аналогична архитектуре энкодедра.\n",
        "\n",
        "Входные аргументы класса \"decoder\" похоже на аргументы класса \"encoder\", исключения — у нас здесь есть параметр, который называется \"output_dimension\" (это размер one-hot векторов, которые подаются на вход декодеру)."
      ],
      "metadata": {
        "id": "4uHfsxKr1bez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6QIm1ulcSfZl"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        self.out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "             \n",
        "        #input = [batch size] батч входных данных\n",
        "        #hidden = [batch size, dec hid dim] # скрытые состояние энкодера\n",
        "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2] выход энкодера\n",
        "        #mask = [batch size, src sent len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "                \n",
        "        #a = [batch size, src sent len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src sent len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
        "        \n",
        "        \"\"\"\n",
        "        torch.bmm - Выполняет пакетное матричное произведение матриц, \n",
        "        хранящихся во входных данных и mat2.\n",
        "        \"\"\"\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output = [sent len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #sent len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        output = self.out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #output = [bsz, output dim]\n",
        "        \n",
        "        return output, hidden.squeeze(0), a.squeeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Она будет содержать внутри себя энкодер, декодер и уметь обрабатывать входные последовательности (то есть вопросы) и выдавать сниппеты в качестве ответов."
      ],
      "metadata": {
        "id": "iQjfwNw84nHO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "MdPPYu-ISfZl"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, pad_idx, sos_idx, eos_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.pad_idx = pad_idx\n",
        "        self.sos_idx = sos_idx\n",
        "        self.eos_idx = eos_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.pad_idx).permute(1, 0)\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src sent len, batch size] \n",
        "        #src_len = [batch size] сниппет с кодом\n",
        "        #trg = [trg sent len, batch size] teacher forcing  (писал в конспекте про это)\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "        \n",
        "        if trg is None:\n",
        "            assert teacher_forcing_ratio == 0, \"Must be zero during inference\"\n",
        "            inference = True\n",
        "            trg = torch.zeros((100, src.shape[1])).long().fill_(self.sos_idx).to(src.device)\n",
        "        else:\n",
        "            inference = False\n",
        "            \n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #тензор для хранения выходных данных декодера\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #tensor to store attention\n",
        "        attentions = torch.zeros(max_len, batch_size, src.shape[0]).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        #это все скрытые состояния входной последовательности\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        output = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "                \n",
        "        #mask = [batch size, src sent len]\n",
        "                \n",
        "        for t in range(1, max_len):\n",
        "            output, hidden, attention = self.decoder(output, hidden, encoder_outputs, mask)\n",
        "            outputs[t] = output\n",
        "            attentions[t] = attention\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "            if inference and output.item() == self.eos_idx:\n",
        "                return outputs[:t], attentions[:t]\n",
        "            \n",
        "        return outputs, attentions\n",
        "\n",
        "# На выход он отдаёт нам output, а также веса attention, которые мы посчитали в модуле attention. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как сказано ранее, входная и выходная размерность определяются размерами словарей. Сделаем так, чтобы количество слоёв у энкодера и декодера, а также размерности векторов скрытых состояний были одинаковыми. Давайте зададим размерность скрытого состояния равную \"100\", размерность для эмбеддингов — \"256\". Также зададим dropout — он будет достаточно большим (\"0.8\"). Далее мы увидим, что если ставить дропаут достаточно маленьким, то сеть будет плохо учиться и результат будет достаточно некрасивым. "
      ],
      "metadata": {
        "id": "Ap-ova6L8KZo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eYftvRX7SfZm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "a314a1b1-de0c-4da1-d532-71a48cd6db38"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8191e4c864fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mEOS_IDX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mENC_HID_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEC_HID_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENC_EMB_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENC_HID_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEC_HID_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENC_DROPOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEC_EMB_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENC_HID_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEC_HID_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEC_DROPOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Attention' is not defined"
          ]
        }
      ],
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "ENC_HID_DIM = 100\n",
        "DEC_HID_DIM = 100\n",
        "ENC_DROPOUT = 0.8\n",
        "DEC_DROPOUT = 0.8\n",
        "PAD_IDX = SRC.vocab.stoi['<pad>']\n",
        "SOS_IDX = TRG.vocab.stoi['<sos>']\n",
        "EOS_IDX = TRG.vocab.stoi['<eos>']\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M89VeqjiSfZm"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgblgDidSfZm"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Модель содержит {count_parameters(model):,} параметров')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKcVfAlESfZn"
      },
      "source": [
        "Then we define our optimizer and criterion. We have already initialized `PAD_IDX` when initializing the model, so we don't need to do it again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shmpPAzLSfZn"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZjlggrWSfZn"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D39Cr-BkSfZn"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, src_len = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, attetion = model(src, src_len, trg, 0.4)\n",
        "        \n",
        "        #trg = [trg sent len, batch size]\n",
        "        #output = [trg sent len, batch size, output dim]\n",
        "        \n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg sent len - 1) * batch size]\n",
        "        #output = [(trg sent len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1DtE2SXSfZo"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, src_len = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, attention = model(src, src_len, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg sent len, batch size]\n",
        "            #output = [trg sent len, batch size, output dim]\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg sent len - 1) * batch size]\n",
        "            #output = [(trg sent len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta21evvfSfZo"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "hitAmMBUSfZo"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'conala_model_attention_test.pt')\n",
        "    \n",
        "    print(f'Эпоха: {epoch+1:02} | Время: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'Перплексия (обучение): {math.exp(train_loss):7.3f}')\n",
        "    print(f'Перплексия (валидация): {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z14jpLfVSfZo"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('conala_model_attention_test.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Перплексия (валидация): {math.exp(test_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRMW81adSfZo"
      },
      "source": [
        "## Предсказание кода по вопросу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skMJ9OFQSfZp"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = tokenize_question(sentence) \n",
        "    tokenized = ['<sos>'] + [t.lower() for t in tokenized] + ['<eos>']\n",
        "    numericalized = [SRC.vocab.stoi[t] for t in tokenized] \n",
        "    sentence_length = torch.LongTensor([len(numericalized)]).to(device) \n",
        "    tensor = torch.LongTensor(numericalized).unsqueeze(1).to(device) \n",
        "    translation_tensor_logits, attention = model(tensor, sentence_length, None, 0) \n",
        "    translation_tensor = torch.argmax(translation_tensor_logits.squeeze(1), 1)\n",
        "    translation = [TRG.vocab.itos[t] for t in translation_tensor]\n",
        "    translation, attention = translation[1:], attention[1:]\n",
        "    return translation, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKAx-vn9SfZp"
      },
      "outputs": [],
      "source": [
        "def display_attention(candidate, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=15)\n",
        "    ax.set_xticklabels([''] + ['<sos>'] + [t.lower() for t in tokenize_question(candidate)] + ['<eos>'], \n",
        "                       rotation=45)\n",
        "    ax.set_yticklabels([''] + translation)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb7vZMeVSfZp"
      },
      "outputs": [],
      "source": [
        "example_idx = 2\n",
        "\n",
        "src = ' '.join(vars(train_data.examples[example_idx])['src'])\n",
        "trg = ' '.join(vars(train_data.examples[example_idx])['trg'])\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ObtHOo8SfZp"
      },
      "outputs": [],
      "source": [
        "translation, attention = translate_sentence(model, src)\n",
        "\n",
        "print('predicted trg = ', ' '.join(translation))\n",
        "\n",
        "display_attention(src, translation, attention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gO0ZCsaSfZp"
      },
      "outputs": [],
      "source": [
        "example_idx = 8\n",
        "\n",
        "src = ' '.join(vars(valid_data.examples[example_idx])['src'])\n",
        "trg = ' '.join(vars(valid_data.examples[example_idx])['trg'])\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecPKuDflSfZp"
      },
      "outputs": [],
      "source": [
        "translation, attention = translate_sentence(model, src)\n",
        "\n",
        "print('predicted trg = ', ' '.join(translation))\n",
        "\n",
        "display_attention(src, translation, attention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NeHIk9hSfZq"
      },
      "outputs": [],
      "source": [
        "example_idx = 4\n",
        "\n",
        "src = ' '.join(vars(test_data.examples[example_idx])['src'])\n",
        "trg = ' '.join(vars(test_data.examples[example_idx])['trg'])\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYa8z1AQSfZq"
      },
      "outputs": [],
      "source": [
        "translation, attention = translate_sentence(model, src)\n",
        "\n",
        "print('predicted trg = ', ''.join(translation))\n",
        "\n",
        "display_attention(src, translation, attention)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "8_seq2seq_code.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}